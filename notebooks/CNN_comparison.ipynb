{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "source": [
    "# Comparison of original CNN and new PyTorch CNN\n",
    "  PyTorch CNN trains with CosAnnealingWithWarmRestarts scheduler \n",
    "  The experiment plot: \n",
    "  <pre>\n",
    "                                   ┌> PT CNN ─Training─> Trained PT CNN ─────┬────> Stats \n",
    "                                   |                                         |\n",
    "  DATASET (70 seqs of 10 families) |                    TEST DATASET (67 seqs of 10 families)                 \n",
    "                                   |                                         |\n",
    "                                   └> Ch CNN ─Training─> Trained Ch CNN ─────┴────> Stats\n",
    "  </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# appending source path \n",
    "sys.path.append(os.sep.join(os.getcwd().split(os.sep)[:-1] + [\"src\"]))\n",
    "sys.path.append(os.sep.join(os.getcwd().split(os.sep)[:-1] + [\"src\", \"original_cnn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RunNN  # our cnn\n",
    "from DataProcessing import AlignmentFilePrepare  # dataset class\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "from subprocess import Popen, PIPE\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# IMPORTANT CONSTANTS\n",
    "BATCH_SIZE= 128\n",
    "EPOCH = 15\n",
    "CPU_ONLY = False\n",
    "\n",
    "\n",
    "def prediction_stats(predicted, true_labels):\n",
    "    # get stats\n",
    "    pred_aff = np.fromiter(map(lambda t: (t[1]==t[0]), combinations(predicted, 2)), dtype=np.int8)\n",
    "    true_aff = np.fromiter(map(lambda t: (t[1]==t[0]), combinations(true_labels, 2)), dtype=np.int8)\n",
    "    tp = np.sum(np.logical_and(true_aff, pred_aff))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(true_aff), np.logical_not(pred_aff)))\n",
    "    fn = np.sum(np.logical_and(true_aff, np.logical_not(pred_aff)))\n",
    "    fp = np.sum(np.logical_and(np.logical_not(true_aff), pred_aff))\n",
    "    print(\"ACC: {:.4f}%\".format(100*(tn+tp)/(tp+tn+fp+fn)))\n",
    "    print(\"F1: {:.4f}\".format(2*tp/(2*tp+fn+fp)))\n",
    "    print(\n",
    "    \"\"\"\n",
    "    pred\\\\real\\t1\\t0\n",
    "            1\\t{}\\t{}\n",
    "            0\\t{}\\t{}\n",
    "             \\t{:.2f}\\t{:.2f}\n",
    "    \"\"\".format(tp, fp, fn, tn, (tp+fn)/(tp+fn+tn+fp), 1-(tp+fn)/(tp+fn+tn+fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets\n",
    "Please, stand by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code is 0\n",
      "Return code is 0\n"
     ]
    }
   ],
   "source": [
    "# training ds\n",
    "cmd = [\n",
    "    \"python\",\n",
    "    \"../src/original_cnn/prepareData.py\",\n",
    "    \"-i\", \"../data/train.fasta\",\n",
    "    \"-o\", \"../data/train\",\n",
    "    \"-t\", \"3\"  # adjust threads\n",
    "]\n",
    "with Popen(cmd) as proc:\n",
    "    print(\"Return code is {}\".format(proc.wait()))\n",
    "\n",
    "# test ds\n",
    "cmd = [\n",
    "    \"python\",\n",
    "    \"../src/original_cnn/prepareData.py\",\n",
    "    \"-i\", \"../data/test.fasta\",\n",
    "    \"-o\", \"../data/test\",\n",
    "    \"-t\", \"3\"  # adjust threads\n",
    "]\n",
    "with Popen(cmd) as proc:\n",
    "    print(\"Return code is {}\".format(proc.wait()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test RunNN\n",
    "### DAFS with nucleotide alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitted. Classes distributed: chi^2 p-val=1.0 (1 means equally distributed classes in test and validation)\n",
      "Data loaded:\n",
      "\tTrain: 4347 alignments\n",
      "\tValidation: 483 alignments\n",
      "Negatives in training set: 91.26%. In val set: 91.72%\n",
      "Data is loaded. Shape: torch.Size([1, 1200, 16])\n",
      "Epoch [1/15], Loss (train/val): 0.2505/0.1785, Accuracy (train/val): 89.5357%/91.7184%, Precision (val): 0.9172, Current lr: 0.00051. Time elapsed: 3.55\n",
      "Epoch [2/15], Loss (train/val): 0.1182/0.0600, Accuracy (train/val): 95.1718%/97.7226%, Precision (val): 0.9758, Current lr: 0.00051. Time elapsed: 5.87\n",
      "Epoch [3/15], Loss (train/val): 0.0292/0.0137, Accuracy (train/val): 99.1039%/99.3789%, Precision (val): 0.9933, Current lr: 0.00051. Time elapsed: 7.55\n",
      "Epoch [4/15], Loss (train/val): 0.0142/0.0055, Accuracy (train/val): 99.4485%/99.5859%, Precision (val): 1.0000, Current lr: 0.00051. Time elapsed: 9.24\n",
      "Epoch [5/15], Loss (train/val): 0.0019/0.0063, Accuracy (train/val): 99.9770%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 10.91\n",
      "Epoch [6/15], Loss (train/val): 0.0004/0.0026, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 12.60\n",
      "Epoch [7/15], Loss (train/val): 0.0001/0.0060, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 14.35\n",
      "Epoch [8/15], Loss (train/val): 0.0001/0.0038, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 16.04\n",
      "Epoch [9/15], Loss (train/val): 0.0001/0.0022, Accuracy (train/val): 100.0000%/100.0000%, Precision (val): 1.0000, Current lr: 0.00051. Time elapsed: 17.71\n",
      "Epoch [10/15], Loss (train/val): 0.0000/0.0015, Accuracy (train/val): 100.0000%/100.0000%, Precision (val): 1.0000, Current lr: 0.00051. Time elapsed: 19.40\n",
      "Epoch [11/15], Loss (train/val): 0.0000/0.0015, Accuracy (train/val): 100.0000%/100.0000%, Precision (val): 1.0000, Current lr: 0.00051. Time elapsed: 21.07\n",
      "Epoch [12/15], Loss (train/val): 0.0000/0.0023, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 22.84\n",
      "Epoch [13/15], Loss (train/val): 0.0000/0.0029, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 24.55\n",
      "Epoch [14/15], Loss (train/val): 0.0000/0.0030, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 26.24\n",
      "Epoch [15/15], Loss (train/val): 0.0000/0.0043, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 27.92\n",
      "TP:\t302\n",
      "FP:\t5\n",
      "FN:\t24\n",
      "TN:\t3451\n",
      "ACC:\t0.9923320994182971\n",
      "PREC:\t0.9837133550488599\n",
      "RECALL:\t0.9263803680981595\n",
      "F1:\t0.9541864139020537\n",
      "ACC: 100.0000%\n",
      "F1: 1.0000\n",
      "\n",
      "    pred\\real\t1\t0\n",
      "            1\t163\t0\n",
      "            0\t0\t1728\n",
      "             \t0.09\t0.91\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = RunNN.main(\n",
    "    dataset=\"../data/train/ncRNApair_data.npy\",\n",
    "    label=\"../data/train/ncRNApair_labe.npy\",\n",
    "    genelabel=\"../data/train/genelabel.txt\",\n",
    "    batchsize=BATCH_SIZE,\n",
    "    epoch=EPOCH,\n",
    "    vpart=0.1,\n",
    "    cpu=CPU_ONLY,\n",
    "    structure=False,\n",
    "    predictor=\"\"  # empty, if you want to train model\n",
    ")\n",
    "# evaluate model\n",
    "dataset = AlignmentFilePrepare(\"../data/test/ncRNApair_data.npy\", \"../data/test/ncRNApair_labe.npy\", \"../data/test/genelabel.txt\")\n",
    "dl = DataLoader(dataset, num_workers=3, shuffle=False, batch_size=BATCH_SIZE)\n",
    "RunNN.predict(model, dl)\n",
    "# save stats\n",
    "with open(\"stats.json\") as fin:\n",
    "    dafs_pt_cnn_history = json.load(fin)\n",
    "dafs_pt_cnn_results = RunNN.predict(model, dl)\n",
    "for key, val in dafs_pt_cnn_results.items():\n",
    "    if key != \"PREDICTIONS\":\n",
    "        print(\"{}:\\t{}\".format(key, val))\n",
    "# clean space\n",
    "del model\n",
    "\n",
    "# clustering test\n",
    "aff_matrix = defaultdict(dict)\n",
    "families = dict()\n",
    "for tup in dafs_pt_cnn_results[\"PREDICTIONS\"]:\n",
    "    aff_matrix[tup[0]][tup[1]] = tup[4].item()\n",
    "    families[tup[0]] = tup[2].item()\n",
    "aff_df = pd.DataFrame(aff_matrix).fillna(0).sort_index()\n",
    "fam_df = pd.DataFrame.from_dict(families, orient=\"index\").sort_index()\n",
    "clusterer = KMeans(n_clusters=10).fit(aff_df)\n",
    "prediction_stats(clusterer.labels_, np.squeeze(fam_df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAFS structure-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitted. Classes distributed: chi^2 p-val=1.0 (1 means equally distributed classes in test and validation)\n",
      "Data loaded:\n",
      "\tTrain: 4347 alignments\n",
      "\tValidation: 483 alignments\n",
      "Negatives in training set: 91.26%. In val set: 91.72%\n",
      "Data is loaded. Shape: torch.Size([1, 1200, 6])\n",
      "Epoch [1/15], Loss (train/val): 0.2842/0.2160, Accuracy (train/val): 91.0274%/91.7184%, Precision (val): 0.9172, Current lr: 0.00051. Time elapsed: 1.54\n",
      "Epoch [2/15], Loss (train/val): 0.1433/0.1009, Accuracy (train/val): 93.9962%/96.0663%, Precision (val): 0.9862, Current lr: 0.00051. Time elapsed: 3.15\n",
      "Epoch [3/15], Loss (train/val): 0.0731/0.0392, Accuracy (train/val): 97.1259%/98.9648%, Precision (val): 0.9910, Current lr: 0.00051. Time elapsed: 5.09\n",
      "Epoch [4/15], Loss (train/val): 0.0306/0.0299, Accuracy (train/val): 98.9651%/99.1718%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 6.54\n",
      "Epoch [5/15], Loss (train/val): 0.0203/0.0227, Accuracy (train/val): 99.1948%/98.9648%, Precision (val): 0.9888, Current lr: 0.00051. Time elapsed: 8.07\n",
      "Epoch [6/15], Loss (train/val): 0.0159/0.0167, Accuracy (train/val): 99.4026%/99.3789%, Precision (val): 0.9933, Current lr: 0.00051. Time elapsed: 9.47\n",
      "Epoch [7/15], Loss (train/val): 0.0175/0.0214, Accuracy (train/val): 99.4256%/99.3789%, Precision (val): 0.9933, Current lr: 0.00051. Time elapsed: 10.92\n",
      "Epoch [8/15], Loss (train/val): 0.0042/0.0139, Accuracy (train/val): 99.9081%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 12.39\n",
      "Epoch [9/15], Loss (train/val): 0.0009/0.0145, Accuracy (train/val): 100.0000%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 13.85\n",
      "Epoch [10/15], Loss (train/val): 0.0003/0.0117, Accuracy (train/val): 100.0000%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 15.31\n",
      "Epoch [11/15], Loss (train/val): 0.0002/0.0078, Accuracy (train/val): 100.0000%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 16.72\n",
      "Epoch [12/15], Loss (train/val): 0.0002/0.0054, Accuracy (train/val): 100.0000%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 18.41\n",
      "Epoch [13/15], Loss (train/val): 0.0001/0.0051, Accuracy (train/val): 100.0000%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 19.98\n",
      "Epoch [14/15], Loss (train/val): 0.0001/0.0053, Accuracy (train/val): 100.0000%/99.5859%, Precision (val): 0.9955, Current lr: 0.00051. Time elapsed: 21.45\n",
      "Epoch [15/15], Loss (train/val): 0.0001/0.0049, Accuracy (train/val): 100.0000%/99.7930%, Precision (val): 0.9977, Current lr: 0.00051. Time elapsed: 22.92\n",
      "TP:\t287.0000\n",
      "FP:\t28.0000\n",
      "FN:\t39.0000\n",
      "TN:\t3428.0000\n",
      "ACC:\t0.9823\n",
      "PREC:\t0.9111\n",
      "RECALL:\t0.8804\n",
      "F1:\t0.8955\n",
      "ACC: 100.0000%\n",
      "F1: 1.0000\n",
      "\n",
      "    pred\\real\t1\t0\n",
      "            1\t163\t0\n",
      "            0\t0\t1728\n",
      "             \t0.09\t0.91\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = RunNN.main(\n",
    "    dataset=\"../data/train/ncRNApair_data.npy\",\n",
    "    label=\"../data/train/ncRNApair_labe.npy\",\n",
    "    genelabel=\"../data/train/genelabel.txt\",\n",
    "    batchsize=BATCH_SIZE,\n",
    "    epoch=EPOCH,\n",
    "    vpart=0.1,\n",
    "    cpu=CPU_ONLY,\n",
    "    structure=True,\n",
    "    predictor=\"\"  # empty, if you want to train model\n",
    ")\n",
    "# evaluate model\n",
    "dataset = AlignmentFilePrepare(\"../data/test/ncRNApair_data.npy\", \"../data/test/ncRNApair_labe.npy\", \"../data/test/genelabel.txt\", structure=True)\n",
    "dl = DataLoader(dataset, num_workers=3, shuffle=True, batch_size=BATCH_SIZE)\n",
    "RunNN.predict(model, dl)\n",
    "# save stats\n",
    "with open(\"stats.json\") as fin:\n",
    "    struct_pt_cnn_history = json.load(fin)\n",
    "struct_pt_cnn_results = RunNN.predict(model, dl)\n",
    "for key, val in struct_pt_cnn_results.items():\n",
    "    if key != \"PREDICTIONS\":\n",
    "        print(\"{}:\\t{:.4f}\".format(key, val))\n",
    "del model\n",
    "\n",
    "# clustering test\n",
    "aff_matrix = defaultdict(dict)\n",
    "families = dict()\n",
    "for tup in struct_pt_cnn_results[\"PREDICTIONS\"]:\n",
    "    aff_matrix[tup[0]][tup[1]] = tup[4].item()\n",
    "    families[tup[0]] = tup[2].item()\n",
    "aff_df = pd.DataFrame(aff_matrix).fillna(0).sort_index()\n",
    "fam_df = pd.DataFrame.from_dict(families, orient=\"index\").sort_index()\n",
    "clusterer = KMeans(n_clusters=10).fit(aff_df)\n",
    "prediction_stats(clusterer.labels_, np.squeeze(fam_df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClustalO data\n",
    "Before run you should have data prepared via PairwiseClustalo_GettingMatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitted. Classes distributed: chi^2 p-val=1.0 (1 means equally distributed classes in test and validation)\n",
      "Data loaded:\n",
      "\tTrain: 4347 alignments\n",
      "\tValidation: 483 alignments\n",
      "Negatives in training set: 91.26%. In val set: 91.72%\n",
      "Data is loaded. Shape: torch.Size([1, 1200, 10])\n",
      "Epoch [1/15], Loss (train/val): 0.3188/0.2882, Accuracy (train/val): 90.1331%/91.7184%, Precision (val): 0.9172, Current lr: 0.00051. Time elapsed: 2.12\n",
      "Epoch [2/15], Loss (train/val): 0.2907/0.2852, Accuracy (train/val): 91.2572%/91.7184%, Precision (val): 0.9172, Current lr: 0.00051. Time elapsed: 4.17\n",
      "Epoch [3/15], Loss (train/val): 0.2935/0.2805, Accuracy (train/val): 91.2590%/91.7184%, Precision (val): 0.9172, Current lr: 0.00051. Time elapsed: 5.76\n",
      "Epoch [4/15], Loss (train/val): 0.2687/0.2720, Accuracy (train/val): 91.2618%/91.7184%, Precision (val): 0.9172, Current lr: 0.00051. Time elapsed: 7.35\n",
      "Epoch [5/15], Loss (train/val): 0.2550/0.2696, Accuracy (train/val): 91.5071%/92.1325%, Precision (val): 0.9210, Current lr: 0.00051. Time elapsed: 9.14\n",
      "Epoch [6/15], Loss (train/val): 0.2472/0.2721, Accuracy (train/val): 92.1341%/92.1325%, Precision (val): 0.9210, Current lr: 0.00051. Time elapsed: 10.70\n",
      "Epoch [7/15], Loss (train/val): 0.2158/0.2748, Accuracy (train/val): 92.3657%/91.9255%, Precision (val): 0.9280, Current lr: 0.00051. Time elapsed: 12.29\n",
      "Epoch [8/15], Loss (train/val): 0.1811/0.2889, Accuracy (train/val): 93.2619%/92.3395%, Precision (val): 0.9265, Current lr: 0.00051. Time elapsed: 13.85\n",
      "Epoch [9/15], Loss (train/val): 0.1883/0.2854, Accuracy (train/val): 92.7296%/91.9255%, Precision (val): 0.9316, Current lr: 0.00051. Time elapsed: 15.45\n",
      "Epoch [10/15], Loss (train/val): 0.1067/0.3538, Accuracy (train/val): 95.8345%/91.3043%, Precision (val): 0.9293, Current lr: 0.00051. Time elapsed: 17.02\n",
      "Epoch [11/15], Loss (train/val): 0.0737/0.4306, Accuracy (train/val): 97.4237%/91.0973%, Precision (val): 0.9310, Current lr: 0.00051. Time elapsed: 18.61\n",
      "Epoch [12/15], Loss (train/val): 0.0697/0.4428, Accuracy (train/val): 97.3346%/90.2692%, Precision (val): 0.9323, Current lr: 0.00051. Time elapsed: 20.25\n",
      "Epoch [13/15], Loss (train/val): 0.0589/0.4725, Accuracy (train/val): 97.8401%/88.1988%, Precision (val): 0.9367, Current lr: 0.00051. Time elapsed: 21.80\n",
      "Epoch [14/15], Loss (train/val): 0.0452/0.5731, Accuracy (train/val): 98.4136%/89.8551%, Precision (val): 0.9283, Current lr: 0.00051. Time elapsed: 23.38\n",
      "Epoch [15/15], Loss (train/val): 0.0287/0.5161, Accuracy (train/val): 99.0790%/89.2340%, Precision (val): 0.9335, Current lr: 0.00051. Time elapsed: 24.95\n",
      "TP:\t53.0000\n",
      "FP:\t153.0000\n",
      "FN:\t273.0000\n",
      "TN:\t3303.0000\n",
      "ACC:\t0.8874\n",
      "PREC:\t0.2573\n",
      "RECALL:\t0.1626\n",
      "F1:\t0.1992\n",
      "ACC: 74.1407%\n",
      "F1: 0.1782\n",
      "\n",
      "    pred\\real\t1\t0\n",
      "            1\t53\t379\n",
      "            0\t110\t1349\n",
      "             \t0.09\t0.91\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = RunNN.main(\n",
    "    dataset=\"../data/train/ncRNApair_data_clustal.npy\",\n",
    "    label=\"../data/train/ncRNApair_labe_clustal.npy\",\n",
    "    genelabel=\"../data/train/genelabel_clustal.txt\",\n",
    "    batchsize=BATCH_SIZE,\n",
    "    epoch=EPOCH,\n",
    "    vpart=0.1,\n",
    "    cpu=CPU_ONLY,\n",
    "    structure=False,\n",
    "    predictor=\"\"  # empty, if you want to train model\n",
    ")\n",
    "# evaluate model\n",
    "dataset = AlignmentFilePrepare(\"../data/test/ncRNApair_data_clustal_test.npy\", \"../data/test/ncRNApair_label_clustal_test.npy\", \"../data/test/genelabel_clustal_test.txt\")\n",
    "dl = DataLoader(dataset, num_workers=3, shuffle=True, batch_size=BATCH_SIZE)\n",
    "RunNN.predict(model, dl)\n",
    "# save stats\n",
    "with open(\"stats.json\") as fin:\n",
    "    struct_pt_cnn_history = json.load(fin)\n",
    "struct_pt_cnn_results = RunNN.predict(model, dl)\n",
    "for key, val in struct_pt_cnn_results.items():\n",
    "    if key != \"PREDICTIONS\":\n",
    "        print(\"{}:\\t{:.4f}\".format(key, val))\n",
    "del model\n",
    "\n",
    "# clustering test\n",
    "aff_matrix = defaultdict(dict)\n",
    "families = dict()\n",
    "for tup in struct_pt_cnn_results[\"PREDICTIONS\"]:\n",
    "    aff_matrix[tup[0]][tup[1]] = tup[4].item()\n",
    "    families[tup[0]] = tup[2].item()\n",
    "aff_df = pd.DataFrame(aff_matrix).fillna(0).sort_index()\n",
    "fam_df = pd.DataFrame.from_dict(families, orient=\"index\").sort_index()\n",
    "clusterer = KMeans(n_clusters=10).fit(aff_df)\n",
    "prediction_stats(clusterer.labels_, np.squeeze(fam_df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test original CNN\n",
    "### Train\n",
    "Clustering was not performed due to poor code documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code is 0\n",
      "Errors: \n"
     ]
    }
   ],
   "source": [
    "# run train\n",
    "# please, stand by\n",
    "cmd = [\n",
    "    \"python\",\n",
    "    \"../src/original_cnn/RNApairClassify.py\",\n",
    "    \"-d\", \"../data/train/ncRNApair_data.npy\",\n",
    "    \"-l\", \"../data/train/ncRNApair_labe.npy\",\n",
    "    \"-gl\", \"../data/train/genelabel.txt\",\n",
    "    \"-b\", str(BATCH_SIZE),\n",
    "    \"-e\", str(EPOCH),\n",
    "    \"-v\", \"6\",  # the max value, which does not fail\n",
    "    \"-g\", \"0\",  # adjust the GPU id\n",
    "    \"-o\", \"../data/results_train\",\n",
    "]\n",
    "with Popen(cmd, stdout=PIPE, stderr=PIPE) as proc:\n",
    "    print(\"Return code is {}\".format(proc.wait()))\n",
    "    print(\"Errors: {}\".format(\"\".join(proc.communicate()[1].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code is 0\n",
      "Errors: \n"
     ]
    }
   ],
   "source": [
    "cmd = [\n",
    "    \"python\",\n",
    "    \"../src/original_cnn/RNApairClassify.py\",\n",
    "    \"-d\", \"../data/test/ncRNApair_data.npy\",\n",
    "    \"-l\", \"../data/test/ncRNApair_labe.npy\",\n",
    "    \"-gl\", \"../data/test/genelabel.txt\",\n",
    "    \"-g\", \"0\",  # adjust the GPU id\n",
    "    \"-v\", \"1\",  # use all data for test\n",
    "    \"-p\", \"../data/results_train/validation5/model_epoch-{}\".format(EPOCH),\n",
    "    \"-o\", \"../data/results_test\",\n",
    "]\n",
    "with Popen(cmd, stdout=PIPE, stderr=PIPE) as proc:\n",
    "    print(\"Return code is {}\".format(proc.wait()))\n",
    "    print(\"Errors: {}\".format(\"\".join(proc.communicate()[1].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "### Spectral clustering on DAFS scores\n",
    "#### Load sequences and make pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from Bio import SeqIO\n",
    "from subprocess import Popen, PIPE\n",
    "from itertools import combinations\n",
    "\n",
    "sequences = list(SeqIO.parse(\"../data/test.fasta\", \"fasta\"))\n",
    "pairs = combinations(enumerate(sequences), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = np.identity(len(sequences))\n",
    "# run dafs\n",
    "for pair in pairs:\n",
    "    SeqIO.write((pair[0][1], pair[1][1]), \"pair.fasta\", \"fasta\")\n",
    "    with Popen([\"dafs\", \"pair.fasta\"], stdout=PIPE) as proc:\n",
    "        result = proc.communicate()[0].decode(\"utf-8\")\n",
    "        sim_matrix[pair[0][0], pair[1][0]] = float(result.split()[1])\n",
    "        sim_matrix[pair[1][0], pair[0][0]] = float(result.split()[1])\n",
    "# clean workspace\n",
    "! rm pair.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/sim_matrix_dafs.npy\", sim_matrix)  # save for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilbumi/anaconda3/envs/sci/lib/python3.7/site-packages/sklearn/cluster/spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 93.1253%\n",
      "F1: 0.7085\n",
      "\n",
      "    pred\\real\t1\t0\n",
      "            1\t158\t125\n",
      "            0\t5\t1603\n",
      "             \t0.09\t0.91\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sim_matrix = np.load(\"../data/sim_matrix_dafs.npy\")\n",
    "clusterer = SpectralClustering()\n",
    "clusterer.fit(sim_matrix)\n",
    "true_labels = list()\n",
    "for seq in sequences:\n",
    "    true_labels.append(int(seq.id.split(\",\")[1]))\n",
    "prediction_stats(clusterer.labels_, true_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
